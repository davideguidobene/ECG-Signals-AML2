{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Conv1D, BatchNormalization, ReLU, Dropout, Add, MaxPooling1D\n",
    "\n",
    "from tensorflow.keras.layers import Bidirectional,LSTM\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Reshape\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "\n",
    "le_file_path = 'evenet_data.pkl'\n",
    "\n",
    "# Load data from the pickle file\n",
    "with open(le_file_path, 'rb') as file:\n",
    "    loaded_data = pickle.load(file)\n",
    "\n",
    "\n",
    "new_data, classes = loaded_data\n",
    "\n",
    "x = new_data[0]\n",
    "\n",
    "def residual_block(x, filters, kernel_size, dropout_rate):\n",
    "    # Convolutional layer\n",
    "    conv = Conv1D(filters=filters,kernel_size= kernel_size,strides=2, \n",
    "                            activation=None,padding='same')(x)\n",
    "    bn = BatchNormalization()(conv)\n",
    "    relu = ReLU()(bn)\n",
    "    dropout = Dropout(dropout_rate)(relu)\n",
    "\n",
    "    fin = Conv1D(filters=filters,kernel_size= kernel_size, \n",
    "                            activation=None,padding='same')(dropout)\n",
    "\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    \n",
    "    # Residual connection\n",
    "    residual = Add()([x, fin])\n",
    "    return residual\n",
    "\n",
    "\n",
    "def residual_block2(x, filters, kernel_size, dropout_rate):\n",
    "    \n",
    "    #print(x.shape)\n",
    "    X = BatchNormalization()(x)\n",
    "    #print(X.shape)\n",
    "    X = ReLU()(X)\n",
    "    #print(X.shape)\n",
    "    X = Dropout(dropout_rate)(X)\n",
    "    #print(X.shape)\n",
    "    X = Conv1D(filters=filters,kernel_size= kernel_size,strides=2, \n",
    "                            activation=None,padding='same')(X)\n",
    "    #print(X.shape)\n",
    "    X = BatchNormalization()(X)\n",
    "    #print(X.shape)\n",
    "    X = ReLU()(X)\n",
    "    #print(X.shape)\n",
    "    X = Dropout(dropout_rate)(X)\n",
    "    #print(X.shape)\n",
    "    X = Conv1D(filters=filters,kernel_size= kernel_size, \n",
    "                            activation=None,padding='same')(X)\n",
    "    #print(X.shape)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    #print(x.shape)\n",
    "\n",
    "    # Residual connection\n",
    "    residual = Add()([x, X])\n",
    "    return residual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-12. -15. -18. ... -63. -64. -64.] [1, 0, 0, 0]\n",
      "122550 122550\n"
     ]
    }
   ],
   "source": [
    "print(new_data[1], classes[1])\n",
    "print(len(new_data), len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 1024, 1)]            0         []                            \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)             (None, 512, 64)              1088      ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 512, 64)              256       ['conv1d[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu (ReLU)                (None, 512, 64)              0         ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)           (None, 256, 64)              65600     ['re_lu[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 256, 64)              256       ['conv1d_1[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_1 (ReLU)              (None, 256, 64)              0         ['batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 256, 64)              0         ['re_lu_1[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1  (None, 256, 64)              0         ['re_lu[0][0]']               \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)           (None, 256, 64)              65600     ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " add (Add)                   (None, 256, 64)              0         ['max_pooling1d[0][0]',       \n",
      "                                                                     'conv1d_2[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 256, 64)              256       ['add[0][0]']                 \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_2 (ReLU)              (None, 256, 64)              0         ['batch_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 256, 64)              0         ['re_lu_2[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)           (None, 128, 64)              65600     ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 128, 64)              256       ['conv1d_3[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_3 (ReLU)              (None, 128, 64)              0         ['batch_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, 128, 64)              0         ['re_lu_3[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPoolin  (None, 128, 64)              0         ['add[0][0]']                 \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)           (None, 128, 64)              65600     ['dropout_2[0][0]']           \n",
      "                                                                                                  \n",
      " add_1 (Add)                 (None, 128, 64)              0         ['max_pooling1d_1[0][0]',     \n",
      "                                                                     'conv1d_4[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_4 (Bat  (None, 128, 64)              256       ['add_1[0][0]']               \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_4 (ReLU)              (None, 128, 64)              0         ['batch_normalization_4[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)         (None, 128, 64)              0         ['re_lu_4[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)           (None, 64, 64)               65600     ['dropout_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (Bat  (None, 64, 64)               256       ['conv1d_5[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_5 (ReLU)              (None, 64, 64)               0         ['batch_normalization_5[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)         (None, 64, 64)               0         ['re_lu_5[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPoolin  (None, 64, 64)               0         ['add_1[0][0]']               \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)           (None, 64, 64)               65600     ['dropout_4[0][0]']           \n",
      "                                                                                                  \n",
      " add_2 (Add)                 (None, 64, 64)               0         ['max_pooling1d_2[0][0]',     \n",
      "                                                                     'conv1d_6[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_6 (Bat  (None, 64, 64)               256       ['add_2[0][0]']               \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_6 (ReLU)              (None, 64, 64)               0         ['batch_normalization_6[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)         (None, 64, 64)               0         ['re_lu_6[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)           (None, 32, 64)               65600     ['dropout_5[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_7 (Bat  (None, 32, 64)               256       ['conv1d_7[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_7 (ReLU)              (None, 32, 64)               0         ['batch_normalization_7[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)         (None, 32, 64)               0         ['re_lu_7[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPoolin  (None, 32, 64)               0         ['add_2[0][0]']               \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)           (None, 32, 64)               65600     ['dropout_6[0][0]']           \n",
      "                                                                                                  \n",
      " add_3 (Add)                 (None, 32, 64)               0         ['max_pooling1d_3[0][0]',     \n",
      "                                                                     'conv1d_8[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_8 (Bat  (None, 32, 64)               256       ['add_3[0][0]']               \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_8 (ReLU)              (None, 32, 64)               0         ['batch_normalization_8[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)         (None, 32, 64)               0         ['re_lu_8[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_9 (Conv1D)           (None, 16, 64)               65600     ['dropout_7[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_9 (Bat  (None, 16, 64)               256       ['conv1d_9[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_9 (ReLU)              (None, 16, 64)               0         ['batch_normalization_9[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)         (None, 16, 64)               0         ['re_lu_9[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPoolin  (None, 16, 64)               0         ['add_3[0][0]']               \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " conv1d_10 (Conv1D)          (None, 16, 64)               65600     ['dropout_8[0][0]']           \n",
      "                                                                                                  \n",
      " add_4 (Add)                 (None, 16, 64)               0         ['max_pooling1d_4[0][0]',     \n",
      "                                                                     'conv1d_10[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_10 (Ba  (None, 16, 64)               256       ['add_4[0][0]']               \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_10 (ReLU)             (None, 16, 64)               0         ['batch_normalization_10[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " bidirectional (Bidirection  (None, 16, 128)              66048     ['re_lu_10[0][0]']            \n",
      " al)                                                                                              \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)         (None, 16, 128)              0         ['bidirectional[0][0]']       \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 16, 1)                129       ['dropout_9[0][0]']           \n",
      "                                                                                                  \n",
      " reshape (Reshape)           (None, 16)                   0         ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 4)                    68        ['reshape[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 726149 (2.77 MB)\n",
      "Trainable params: 724741 (2.76 MB)\n",
      "Non-trainable params: 1408 (5.50 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(1024,1))\n",
    "Conv = Conv1D(filters=64,kernel_size= 16,strides=2,activation=None,padding='same')(inputs)\n",
    "bn = BatchNormalization()(Conv)\n",
    "relu = ReLU()(bn)\n",
    "\n",
    "#print(relu.shape)\n",
    "#model = Model(inputs,relu)\n",
    "\n",
    "res = residual_block(relu,64,16,0.2)\n",
    "\n",
    "#print(res.shape)\n",
    "#model = Model(inputs,res)\n",
    "\n",
    "num_residual_layers = 4\n",
    "\n",
    "for i in range(num_residual_layers):\n",
    "    res = residual_block2(res,64,16,0.2)\n",
    "    #print(res.shape)\n",
    "\n",
    "#model = Model(inputs,res)\n",
    "\n",
    "last_layer = BatchNormalization()(res)\n",
    "last_layer = ReLU() (last_layer)\n",
    "last_layer = Bidirectional(LSTM(64, return_sequences=True))(last_layer)\n",
    "#print(last_layer.shape)\n",
    "\n",
    "last_layer = Dropout(0.2)(last_layer)\n",
    "\n",
    "features = Dense(1, activation='sigmoid')(last_layer)\n",
    "features = (Reshape((16,), input_shape=(1, 16, 1)))(features)\n",
    "\n",
    "#print(features.shape)\n",
    "#model = Model(inputs,features)\n",
    "\n",
    "logits = Dense(units=4, activation='softmax') (features)\n",
    "#print(logits.shape)\n",
    "model = Model(inputs,logits)\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "# works up to here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 13s 13s/step - loss: 1.7483 - accuracy: 0.0000e+00 - val_loss: 1.5838 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.4927 - accuracy: 0.0000e+00 - val_loss: 1.5097 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.3022 - accuracy: 0.0000e+00 - val_loss: 1.3842 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.1373 - accuracy: 0.0000e+00 - val_loss: 1.3742 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.0114 - accuracy: 1.0000 - val_loss: 1.3776 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.9230 - accuracy: 1.0000 - val_loss: 1.3728 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.8275 - accuracy: 1.0000 - val_loss: 1.3900 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7133 - accuracy: 1.0000 - val_loss: 1.3978 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6662 - accuracy: 1.0000 - val_loss: 1.4242 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6253 - accuracy: 1.0000 - val_loss: 1.4324 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x199385e95a0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = new_data[0]\n",
    "x_train = tf.reshape(x_train, shape=(1,1024,1)) \n",
    "y_train = tf.constant([1,0,0,0],shape=(1,4))\n",
    "\n",
    "x_val = new_data[1]\n",
    "x_val = tf.reshape(x_val, shape=(1,1024,1)) \n",
    "y_val = tf.constant([1,0,0,0],shape=(1,4))\n",
    "\n",
    "\n",
    "\n",
    "history = model.fit(x=x_train,y=y_train,epochs=10,batch_size=1,validation_data=(x_val,y_val))\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "300/300 [==============================] - 9s 31ms/step - loss: 1.6248 - accuracy: 0.2633 - val_loss: 2.0365 - val_accuracy: 0.2200\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 9s 31ms/step - loss: 1.4871 - accuracy: 0.2633 - val_loss: 1.4718 - val_accuracy: 0.2500\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 9s 31ms/step - loss: 1.3143 - accuracy: 0.3167 - val_loss: 1.4270 - val_accuracy: 0.2300\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 9s 31ms/step - loss: 1.1732 - accuracy: 0.4167 - val_loss: 1.4242 - val_accuracy: 0.2800\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 9s 30ms/step - loss: 1.0038 - accuracy: 0.4933 - val_loss: 1.4535 - val_accuracy: 0.2900\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 9s 31ms/step - loss: 0.9438 - accuracy: 0.5133 - val_loss: 1.4247 - val_accuracy: 0.2500\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 10s 32ms/step - loss: 0.7899 - accuracy: 0.6933 - val_loss: 1.3636 - val_accuracy: 0.3500\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 10s 33ms/step - loss: 0.7143 - accuracy: 0.7700 - val_loss: 1.3222 - val_accuracy: 0.3600\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 9s 32ms/step - loss: 0.6211 - accuracy: 0.8133 - val_loss: 1.4620 - val_accuracy: 0.2700\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 9s 32ms/step - loss: 0.6023 - accuracy: 0.8500 - val_loss: 1.3783 - val_accuracy: 0.3300\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\EK\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\engine\\training.py\", line 2341, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\EK\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\engine\\training.py\", line 2327, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\EK\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\engine\\training.py\", line 2315, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\EK\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\engine\\training.py\", line 2283, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\EK\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\EK\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\engine\\input_spec.py\", line 253, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'model' (type Functional).\n    \n    Input 0 of layer \"conv1d\" is incompatible with the layer: expected min_ndim=3, found ndim=1. Full shape received: (32,)\n    \n    Call arguments received by layer 'model' (type Functional):\n      • inputs=tf.Tensor(shape=(32,), dtype=float32)\n      • training=False\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 30\u001b[0m\n\u001b[0;32m     25\u001b[0m Y_val \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mreshape(Y_val,shape\u001b[39m=\u001b[39m(\u001b[39mlen\u001b[39m(Y_val),\u001b[39m4\u001b[39m,\u001b[39m1\u001b[39m))\n\u001b[0;32m     29\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfit(x\u001b[39m=\u001b[39mX_train,y\u001b[39m=\u001b[39mY_train,epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m,batch_size\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,validation_data\u001b[39m=\u001b[39m(X_val,Y_val))\n\u001b[1;32m---> 30\u001b[0m \u001b[39mprint\u001b[39m(model\u001b[39m.\u001b[39;49mpredict(new_data[\u001b[39m400\u001b[39;49m]))\n\u001b[0;32m     31\u001b[0m \u001b[39mprint\u001b[39m(classes[\u001b[39m400\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file4rjcp5tz.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\EK\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\engine\\training.py\", line 2341, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\EK\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\engine\\training.py\", line 2327, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\EK\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\engine\\training.py\", line 2315, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\EK\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\engine\\training.py\", line 2283, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\EK\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\EK\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\engine\\input_spec.py\", line 253, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'model' (type Functional).\n    \n    Input 0 of layer \"conv1d\" is incompatible with the layer: expected min_ndim=3, found ndim=1. Full shape received: (32,)\n    \n    Call arguments received by layer 'model' (type Functional):\n      • inputs=tf.Tensor(shape=(32,), dtype=float32)\n      • training=False\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "x_data = new_data[:1000]\n",
    "y_data = classes[:1000]\n",
    "\n",
    "##shuffle\n",
    "import random\n",
    "zipped = list(zip(x_data, y_data))\n",
    "random.shuffle(zipped)\n",
    "x_data, y_data = zip(*zipped)\n",
    "#print(tf.shape(X_train), tf.shape(Y_train))\n",
    "#print(len(X_train), len(Y_train))\n",
    "\n",
    "X_train = x_data[:300]\n",
    "Y_train = y_data[:300]\n",
    "X_train = tf.convert_to_tensor(X_train)\n",
    "X_train = tf.reshape(X_train, shape=(len(X_train),1024,1)) \n",
    "Y_train = tf.convert_to_tensor(Y_train)\n",
    "Y_train = tf.reshape(Y_train, shape=(len(Y_train),4,1))\n",
    "\n",
    "\n",
    "X_val = x_data[900:1000]\n",
    "Y_val = y_data[900:1000]\n",
    "X_val = tf.convert_to_tensor(X_val)\n",
    "X_val = tf.reshape(X_val,shape=(len(X_val),1024,1))\n",
    "Y_val = tf.convert_to_tensor(Y_val)\n",
    "Y_val = tf.reshape(Y_val,shape=(len(Y_val),4,1))\n",
    "\n",
    "\n",
    "\n",
    "history = model.fit(x=X_train,y=Y_train,epochs=10,batch_size=1,validation_data=(X_val,Y_val))\n",
    "print(model.predict(new_data[400]))\n",
    "print(classes[400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to save the model do this: \n",
    "\n",
    "model.save(\"myModel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to load a model do this:\n",
    "\n",
    "loaded_model = tf.keras.models.load_model(\"myModel.h5\")\n",
    "\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_to_last_name = loaded_model.layers[-2].name\n",
    "\n",
    "feature_extraction_model = Model(inputs = loaded_model.input,outputs=loaded_model.get_layer(second_to_last_name).output)\n",
    "\n",
    "input_data = new_data[5]\n",
    "input_data = tf.reshape(input_data, shape=(1,1024,1))\n",
    "\n",
    "features = feature_extraction_model(input_data)\n",
    "\n",
    "features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
